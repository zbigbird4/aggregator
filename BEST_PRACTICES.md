# Aggregator æœ€ä½³å®è·µæŒ‡å—

> **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’Œè¿ç»´çš„æœ€ä½³å®è·µ**

---

## ğŸ“– ç›®å½•

- [1. å®‰å…¨æœ€ä½³å®è·µ](#1-å®‰å…¨æœ€ä½³å®è·µ)
- [2. æ€§èƒ½ä¼˜åŒ–](#2-æ€§èƒ½ä¼˜åŒ–)
- [3. ç›‘æ§å’Œå‘Šè­¦](#3-ç›‘æ§å’Œå‘Šè­¦)
- [4. å¤‡ä»½ç­–ç•¥](#4-å¤‡ä»½ç­–ç•¥)
- [5. å®¹å™¨é•œåƒæ›´æ–°ç­–ç•¥](#5-å®¹å™¨é•œåƒæ›´æ–°ç­–ç•¥)
- [6. æ—¥å¿—ç®¡ç†](#6-æ—¥å¿—ç®¡ç†)
- [7. èµ„æºç®¡ç†](#7-èµ„æºç®¡ç†)
- [8. ç½‘ç»œé…ç½®](#8-ç½‘ç»œé…ç½®)
- [9. æ•…éšœæ¢å¤](#9-æ•…éšœæ¢å¤)
- [10. å¼€å‘ç¯å¢ƒå®è·µ](#10-å¼€å‘ç¯å¢ƒå®è·µ)

---

## 1. å®‰å…¨æœ€ä½³å®è·µ

### 1.1 æ•æ„Ÿä¿¡æ¯ç®¡ç†

#### âœ… **ä½¿ç”¨ç¯å¢ƒå˜é‡è€Œéç¡¬ç¼–ç **

âŒ **ä¸å¥½çš„åšæ³•**ï¼š
```yaml
environment:
  - GIST_PAT=ghp_1234567890abcdefghijk  # ç¡¬ç¼–ç åœ¨é…ç½®æ–‡ä»¶ä¸­
```

âœ… **å¥½çš„åšæ³•**ï¼š
```yaml
environment:
  - GIST_PAT=${GIST_PAT}  # ä» .env æ–‡ä»¶è¯»å–
```

#### âœ… **ä¿æŠ¤ .env æ–‡ä»¶**

```bash
# è®¾ç½®ä¸¥æ ¼çš„æ–‡ä»¶æƒé™
chmod 600 .env
chown $USER:$USER .env

# ç¡®ä¿ .env åœ¨ .gitignore ä¸­
echo ".env" >> .gitignore

# éªŒè¯æƒé™
ls -la .env
# åº”è¯¥æ˜¾ç¤º: -rw------- (600)
```

#### âœ… **ä½¿ç”¨ Docker Secretsï¼ˆSwarm/Kubernetesï¼‰**

Docker Swarm ç¤ºä¾‹ï¼š
```bash
# åˆ›å»º secret
echo "ghp_your_token" | docker secret create gist_pat -

# ä½¿ç”¨ secret
services:
  aggregator:
    secrets:
      - gist_pat
    environment:
      - GIST_PAT_FILE=/run/secrets/gist_pat

secrets:
  gist_pat:
    external: true
```

Kubernetes ç¤ºä¾‹ï¼š
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: aggregator-secrets
type: Opaque
stringData:
  GIST_PAT: "ghp_your_token"
```

### 1.2 ç½‘ç»œå®‰å…¨

#### âœ… **ä½¿ç”¨å†…éƒ¨ç½‘ç»œ**

```yaml
services:
  aggregator:
    networks:
      - internal-network

networks:
  internal-network:
    internal: true  # ä¸å…è®¸å¤–éƒ¨è®¿é—®
```

#### âœ… **æœ€å°åŒ–ç«¯å£æš´éœ²**

```yaml
# Aggregator é»˜è®¤ä¸éœ€è¦æš´éœ²ç«¯å£
# åªåœ¨å¿…è¦æ—¶æš´éœ²
services:
  aggregator:
    # ports: []  # ä¸æš´éœ²ä»»ä½•ç«¯å£
```

#### âœ… **é…ç½®é˜²ç«å¢™**

```bash
# UFW (Ubuntu)
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow 22/tcp  # åªå…è®¸ SSH
sudo ufw enable

# æŸ¥çœ‹çŠ¶æ€
sudo ufw status
```

### 1.3 å®¹å™¨å®‰å…¨

#### âœ… **ä»¥é root ç”¨æˆ·è¿è¡Œ**

```dockerfile
# åœ¨ Dockerfile ä¸­
RUN useradd -m -u 1000 aggregator
USER aggregator
```

æˆ–åœ¨ docker-compose.yml ä¸­ï¼š
```yaml
services:
  aggregator:
    user: "1000:1000"
```

#### âœ… **åªè¯»æ–‡ä»¶ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰**

```yaml
services:
  aggregator:
    read_only: true
    tmpfs:
      - /tmp
      - /aggregator/data
```

#### âœ… **é™åˆ¶å®¹å™¨èƒ½åŠ›**

```yaml
services:
  aggregator:
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE  # åªæ·»åŠ å¿…éœ€çš„èƒ½åŠ›
```

### 1.4 é•œåƒå®‰å…¨

#### âœ… **ä½¿ç”¨å›ºå®šç‰ˆæœ¬æ ‡ç­¾**

âŒ **ä¸å¥½çš„åšæ³•**ï¼š
```yaml
image: wzdnzd/aggregator:latest  # ç”Ÿäº§ç¯å¢ƒä¸æ¨è
```

âœ… **å¥½çš„åšæ³•**ï¼š
```yaml
image: wzdnzd/aggregator:v1.0.0  # ä½¿ç”¨å›ºå®šç‰ˆæœ¬
```

#### âœ… **å®šæœŸæ‰«æé•œåƒæ¼æ´**

```bash
# ä½¿ç”¨ Trivy æ‰«æ
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy:latest image wzdnzd/aggregator:latest

# ä½¿ç”¨ Grype æ‰«æ
grype wzdnzd/aggregator:latest

# ä½¿ç”¨ Docker Scan
docker scan wzdnzd/aggregator:latest
```

#### âœ… **éªŒè¯é•œåƒç­¾å**

```bash
# å¯ç”¨ Docker Content Trust
export DOCKER_CONTENT_TRUST=1
docker pull wzdnzd/aggregator:latest
```

---

## 2. æ€§èƒ½ä¼˜åŒ–

### 2.1 èµ„æºé…ç½®

#### âœ… **åˆç†è®¾ç½®èµ„æºé™åˆ¶**

```yaml
services:
  aggregator:
    deploy:
      resources:
        limits:
          cpus: '2'         # æœ€å¤§ 2 ä¸ª CPU
          memory: 2G        # æœ€å¤§ 2GB å†…å­˜
        reservations:
          cpus: '1'         # è‡³å°‘ä¿è¯ 1 ä¸ª CPU
          memory: 512M      # è‡³å°‘ä¿è¯ 512MB å†…å­˜
```

**æ¨èé…ç½®ï¼ˆæ ¹æ®åœºæ™¯ï¼‰**ï¼š

| åœºæ™¯ | CPU é™åˆ¶ | å†…å­˜é™åˆ¶ | è¯´æ˜ |
|-----|---------|---------|------|
| **è½»é‡ä½¿ç”¨** | 1 CPU | 1GB | ä¸ªäººä½¿ç”¨ï¼Œä»£ç†å°‘ |
| **ä¸­ç­‰ä½¿ç”¨** | 2 CPU | 2GB | æ­£å¸¸ä½¿ç”¨ï¼Œé€‚ä¸­ä»£ç†é‡ |
| **é‡åº¦ä½¿ç”¨** | 4 CPU | 4GB | å¤§é‡ä»£ç†ï¼Œé«˜å¹¶å‘ |
| **ä¼ä¸šçº§** | 8 CPU | 8GB | ç”Ÿäº§ç¯å¢ƒï¼Œé«˜å¯ç”¨ |

### 2.2 å¹¶å‘ä¼˜åŒ–

#### âœ… **æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´å¹¶å‘**

```bash
# æŸ¥çœ‹ CPU æ ¸å¿ƒæ•°
nproc

# å¹¶å‘æ•°å»ºè®®ï¼šCPU æ ¸å¿ƒæ•° Ã— 2 åˆ° 4
# ä¾‹å¦‚ï¼š4 æ ¸ CPUï¼Œå¹¶å‘æ•°å¯è®¾ä¸º 8 åˆ° 16

# ä½¿ç”¨è‡ªå®šä¹‰å¹¶å‘æ•°
docker exec aggregator python -u subscribe/collect.py -n 16
```

#### âœ… **æ‰¹é‡å¤„ç†**

```python
# åœ¨è‡ªå®šä¹‰é…ç½®ä¸­
{
  "batch_size": 100,          # æ¯æ‰¹å¤„ç† 100 ä¸ªä»£ç†
  "max_concurrent": 32,       # æœ€å¤§å¹¶å‘æ•°
  "timeout": 5000             # è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
}
```

### 2.3 å­˜å‚¨ä¼˜åŒ–

#### âœ… **ä½¿ç”¨ SSD å­˜å‚¨**

```yaml
volumes:
  aggregator-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/ssd/aggregator/data  # æŒ‚è½½åˆ° SSD
```

#### âœ… **ä½¿ç”¨å·ç¼“å­˜**

```yaml
volumes:
  - ./data:/aggregator/data:cached  # macOS/Windows ä¼˜åŒ–
```

### 2.4 ç½‘ç»œä¼˜åŒ–

#### âœ… **ä½¿ç”¨ host ç½‘ç»œæ¨¡å¼ï¼ˆLinuxï¼‰**

```yaml
services:
  aggregator:
    network_mode: host  # æ€§èƒ½æœ€å¥½ï¼Œä½†å®‰å…¨æ€§è¾ƒä½
```

#### âœ… **ç¦ç”¨ä¸å¿…è¦çš„ç½‘ç»œåŠŸèƒ½**

```yaml
services:
  aggregator:
    networks:
      aggregator-network:
        ipv6_address: false  # å¦‚æœä¸éœ€è¦ IPv6
```

---

## 3. ç›‘æ§å’Œå‘Šè­¦

### 3.1 å¥åº·æ£€æŸ¥

#### âœ… **é…ç½®å®¹å™¨å¥åº·æ£€æŸ¥**

```yaml
services:
  aggregator:
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s         # æ¯ 30 ç§’æ£€æŸ¥ä¸€æ¬¡
      timeout: 10s          # è¶…æ—¶æ—¶é—´
      retries: 3            # å¤±è´¥ 3 æ¬¡è®¤ä¸ºä¸å¥åº·
      start_period: 30s     # å¯åŠ¨å 30 ç§’æ‰å¼€å§‹æ£€æŸ¥
```

#### âœ… **è‡ªåŠ¨é‡å¯ç­–ç•¥**

```yaml
services:
  aggregator:
    restart: unless-stopped  # æ¨èï¼šé™¤éæ‰‹åŠ¨åœæ­¢ï¼Œå¦åˆ™æ€»æ˜¯é‡å¯
    # restart: always        # æ€»æ˜¯é‡å¯
    # restart: on-failure    # åªåœ¨å¤±è´¥æ—¶é‡å¯
```

### 3.2 èµ„æºç›‘æ§

#### âœ… **ä½¿ç”¨ Prometheus + Grafana**

```yaml
# æ·»åŠ  cAdvisor ç›‘æ§å®¹å™¨
services:
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
    ports:
      - "8080:8080"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
```

**prometheus.yml é…ç½®**ï¼š
```yaml
scrape_configs:
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
```

### 3.3 æ—¥å¿—ç›‘æ§

#### âœ… **é…ç½®æ—¥å¿—å‘Šè­¦**

åˆ›å»º `/opt/aggregator/scripts/log-monitor.sh`ï¼š

```bash
#!/bin/bash
# ç›‘æ§é”™è¯¯æ—¥å¿—å¹¶å‘Šè­¦

LOG_FILE="/opt/aggregator/logs/aggregator.log"
ERROR_THRESHOLD=10
WEBHOOK_URL="${WEBHOOK_URL:-}"

# ç»Ÿè®¡æœ€è¿‘ 1 å°æ—¶çš„é”™è¯¯æ•°
ERROR_COUNT=$(docker logs aggregator --since 1h 2>&1 | grep -c "ERROR")

if [ "$ERROR_COUNT" -gt "$ERROR_THRESHOLD" ]; then
    MESSAGE="âš ï¸ Aggregator åœ¨è¿‡å» 1 å°æ—¶å‡ºç° $ERROR_COUNT ä¸ªé”™è¯¯"
    
    # å‘é€é€šçŸ¥
    if [ -n "$WEBHOOK_URL" ]; then
        curl -X POST "$WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d "{\"text\":\"$MESSAGE\"}"
    fi
    
    echo "$MESSAGE"
fi
```

å®šæ—¶è¿è¡Œï¼š
```bash
# æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
0 * * * * /opt/aggregator/scripts/log-monitor.sh >> /opt/aggregator/logs/monitor.log 2>&1
```

### 3.4 å‘Šè­¦é€šçŸ¥

#### âœ… **é…ç½® Email é€šçŸ¥**

ä½¿ç”¨ Watchtower çš„é‚®ä»¶é€šçŸ¥ï¼š

```yaml
services:
  watchtower:
    environment:
      - WATCHTOWER_NOTIFICATIONS=email
      - WATCHTOWER_NOTIFICATION_EMAIL_FROM=aggregator@yourdomain.com
      - WATCHTOWER_NOTIFICATION_EMAIL_TO=admin@yourdomain.com
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER=smtp.gmail.com
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=your_email@gmail.com
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=your_app_password
```

#### âœ… **é…ç½® Webhook é€šçŸ¥**

```yaml
environment:
  - WATCHTOWER_NOTIFICATIONS=shoutrrr
  - WATCHTOWER_NOTIFICATION_URL=generic+https://your-webhook-url.com
```

æ”¯æŒçš„é€šçŸ¥æ–¹å¼ï¼š
- Email
- Slack
- Discord
- Telegram
- Microsoft Teams
- Webhook (Generic)

---

## 4. å¤‡ä»½ç­–ç•¥

### 4.1 è‡ªåŠ¨å¤‡ä»½

#### âœ… **æ¯æ—¥è‡ªåŠ¨å¤‡ä»½è„šæœ¬**

åˆ›å»º `/opt/aggregator/scripts/daily-backup.sh`ï¼š

```bash
#!/bin/bash
set -e

BACKUP_DIR="/opt/aggregator/backups"
DATA_DIR="/opt/aggregator/data"
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/backup_$TIMESTAMP.tar.gz"

echo "ğŸ“¦ å¼€å§‹å¤‡ä»½: $TIMESTAMP"

# åœæ­¢å®¹å™¨ï¼ˆå¯é€‰ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ï¼‰
docker-compose -f /opt/aggregator/docker-compose.yml stop aggregator

# å¤‡ä»½æ•°æ®
tar -czf "$BACKUP_FILE" -C "$DATA_DIR" .

# å¯åŠ¨å®¹å™¨
docker-compose -f /opt/aggregator/docker-compose.yml start aggregator

# éªŒè¯å¤‡ä»½
if [ -f "$BACKUP_FILE" ]; then
    echo "âœ… å¤‡ä»½æˆåŠŸ: $BACKUP_FILE"
    echo "ğŸ“Š å¤‡ä»½å¤§å°: $(du -sh "$BACKUP_FILE" | cut -f1)"
else
    echo "âŒ å¤‡ä»½å¤±è´¥"
    exit 1
fi

# åˆ é™¤æ—§å¤‡ä»½
find "$BACKUP_DIR" -name "backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete
echo "ğŸ—‘ï¸  å·²åˆ é™¤ $RETENTION_DAYS å¤©å‰çš„å¤‡ä»½"

# ä¸Šä¼ åˆ°è¿œç¨‹ï¼ˆå¯é€‰ï¼‰
# rsync -avz "$BACKUP_FILE" user@remote:/backups/aggregator/
```

#### âœ… **é…ç½®å®šæ—¶ä»»åŠ¡**

```bash
# ç¼–è¾‘ crontab
crontab -e

# æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½
0 2 * * * /opt/aggregator/scripts/daily-backup.sh >> /opt/aggregator/logs/backup.log 2>&1

# æ¯å‘¨æ—¥å‡Œæ™¨ 3 ç‚¹å¤‡ä»½åˆ°è¿œç¨‹
0 3 * * 0 rsync -avz /opt/aggregator/backups/ user@remote:/backups/aggregator/
```

### 4.2 å¤‡ä»½éªŒè¯

#### âœ… **å®šæœŸéªŒè¯å¤‡ä»½å¯æ¢å¤æ€§**

åˆ›å»º `/opt/aggregator/scripts/verify-backup.sh`ï¼š

```bash
#!/bin/bash
set -e

BACKUP_FILE="$1"
TEST_DIR="/tmp/backup-test-$$"

if [ -z "$BACKUP_FILE" ]; then
    echo "ç”¨æ³•: $0 <backup_file>"
    exit 1
fi

echo "ğŸ” éªŒè¯å¤‡ä»½: $BACKUP_FILE"

# åˆ›å»ºæµ‹è¯•ç›®å½•
mkdir -p "$TEST_DIR"

# è§£å‹å¤‡ä»½
tar -xzf "$BACKUP_FILE" -C "$TEST_DIR"

# æ£€æŸ¥å…³é”®æ–‡ä»¶
if [ -f "$TEST_DIR/proxies.txt" ]; then
    echo "âœ… proxies.txt å­˜åœ¨"
else
    echo "âŒ proxies.txt ç¼ºå¤±"
    exit 1
fi

# æ¸…ç†
rm -rf "$TEST_DIR"

echo "âœ… å¤‡ä»½éªŒè¯é€šè¿‡"
```

### 4.3 å¼‚åœ°å¤‡ä»½

#### âœ… **ä½¿ç”¨ rsync åŒæ­¥åˆ°è¿œç¨‹**

```bash
# åŒæ­¥åˆ°è¿œç¨‹æœåŠ¡å™¨
rsync -avz --delete \
  /opt/aggregator/backups/ \
  user@remote:/backups/aggregator/

# ä½¿ç”¨ SSH å¯†é’¥è®¤è¯ï¼ˆæ¨èï¼‰
ssh-keygen -t rsa -b 4096
ssh-copy-id user@remote
```

#### âœ… **ä½¿ç”¨äº‘å­˜å‚¨ï¼ˆS3/OSSï¼‰**

```bash
# å®‰è£… AWS CLI
pip install awscli

# é…ç½® AWS å‡­è¯
aws configure

# åŒæ­¥åˆ° S3
aws s3 sync /opt/aggregator/backups/ s3://your-bucket/aggregator/backups/

# æˆ–ä½¿ç”¨ rcloneï¼ˆæ”¯æŒå¤šç§äº‘å­˜å‚¨ï¼‰
rclone sync /opt/aggregator/backups/ remote:aggregator/backups/
```

---

## 5. å®¹å™¨é•œåƒæ›´æ–°ç­–ç•¥

### 5.1 æ‰‹åŠ¨æ›´æ–°

#### âœ… **æœ‰è®¡åˆ’çš„æ›´æ–°æµç¨‹**

```bash
#!/bin/bash
# æ›´æ–°æµç¨‹è„šæœ¬

set -e

echo "ğŸ“¦ å¼€å§‹æ›´æ–° Aggregator..."

# 1. å¤‡ä»½å½“å‰æ•°æ®
echo "1ï¸âƒ£ å¤‡ä»½æ•°æ®..."
./scripts/daily-backup.sh

# 2. æ‹‰å–æ–°é•œåƒ
echo "2ï¸âƒ£ æ‹‰å–æ–°é•œåƒ..."
docker pull wzdnzd/aggregator:latest

# 3. åœæ­¢æ—§å®¹å™¨
echo "3ï¸âƒ£ åœæ­¢å®¹å™¨..."
docker-compose down

# 4. å¯åŠ¨æ–°å®¹å™¨
echo "4ï¸âƒ£ å¯åŠ¨å®¹å™¨..."
docker-compose up -d

# 5. ç­‰å¾…å¯åŠ¨
sleep 10

# 6. éªŒè¯è¿è¡ŒçŠ¶æ€
echo "5ï¸âƒ£ éªŒè¯çŠ¶æ€..."
if docker ps | grep -q aggregator; then
    echo "âœ… æ›´æ–°æˆåŠŸ"
    docker-compose logs --tail=20 aggregator
else
    echo "âŒ æ›´æ–°å¤±è´¥ï¼Œæ­£åœ¨å›æ»š..."
    # å›æ»šåˆ°æ—§ç‰ˆæœ¬
    docker-compose down
    docker tag wzdnzd/aggregator:backup wzdnzd/aggregator:latest
    docker-compose up -d
    exit 1
fi

# 7. æ¸…ç†æ—§é•œåƒ
echo "6ï¸âƒ£ æ¸…ç†æ—§é•œåƒ..."
docker image prune -a -f

echo "âœ… æ›´æ–°å®Œæˆï¼"
```

### 5.2 è‡ªåŠ¨æ›´æ–°ï¼ˆWatchtowerï¼‰

#### âœ… **ç”Ÿäº§ç¯å¢ƒé…ç½®**

```yaml
services:
  watchtower:
    image: containrrr/watchtower:latest
    environment:
      # æ¯å¤©å‡Œæ™¨ 2 ç‚¹æ£€æŸ¥æ›´æ–°
      - WATCHTOWER_SCHEDULE=0 0 2 * * *
      
      # æ¸…ç†æ—§é•œåƒ
      - WATCHTOWER_CLEANUP=true
      
      # åªæ›´æ–°æœ‰æ ‡ç­¾çš„å®¹å™¨
      - WATCHTOWER_LABEL_ENABLE=true
      
      # ç›‘æ§æ¨¡å¼ï¼ˆåªé€šçŸ¥ä¸æ›´æ–°ï¼‰
      # - WATCHTOWER_MONITOR_ONLY=true
      
      # é€šçŸ¥é…ç½®
      - WATCHTOWER_NOTIFICATIONS=email
      - WATCHTOWER_NOTIFICATION_EMAIL_FROM=${EMAIL_FROM}
      - WATCHTOWER_NOTIFICATION_EMAIL_TO=${EMAIL_TO}
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER=${EMAIL_SERVER}
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PORT=587
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_USER=${EMAIL_USER}
      - WATCHTOWER_NOTIFICATION_EMAIL_SERVER_PASSWORD=${EMAIL_PASSWORD}
    
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
```

### 5.3 ç‰ˆæœ¬æ§åˆ¶

#### âœ… **ä½¿ç”¨è¯­ä¹‰åŒ–ç‰ˆæœ¬**

```yaml
# å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨ latest
image: wzdnzd/aggregator:latest

# æµ‹è¯•ç¯å¢ƒï¼šä½¿ç”¨ä¸»åˆ†æ”¯ç‰ˆæœ¬
image: wzdnzd/aggregator:main

# ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨å›ºå®šç‰ˆæœ¬
image: wzdnzd/aggregator:v1.0.0

# æˆ–ä½¿ç”¨æ¬¡ç‰ˆæœ¬ï¼ˆæ¥å—è¡¥ä¸æ›´æ–°ï¼‰
image: wzdnzd/aggregator:v1.0
```

---

## 6. æ—¥å¿—ç®¡ç†

### 6.1 æ—¥å¿—è½®è½¬

#### âœ… **é…ç½® Docker æ—¥å¿—è½®è½¬**

```yaml
services:
  aggregator:
    logging:
      driver: "json-file"
      options:
        max-size: "50m"      # å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§ 50MB
        max-file: "10"       # ä¿ç•™ 10 ä¸ªæ—¥å¿—æ–‡ä»¶
        compress: "true"     # å‹ç¼©æ—§æ—¥å¿—
```

#### âœ… **ä½¿ç”¨ logrotate**

åˆ›å»º `/etc/logrotate.d/aggregator`ï¼š

```
/opt/aggregator/logs/*.log {
    daily                    # æ¯å¤©è½®è½¬
    rotate 30                # ä¿ç•™ 30 å¤©
    compress                 # å‹ç¼©æ—§æ—¥å¿—
    delaycompress            # å»¶è¿Ÿå‹ç¼©ï¼ˆä¸‹æ¬¡è½®è½¬æ—¶å‹ç¼©ï¼‰
    notifempty               # ç©ºæ–‡ä»¶ä¸è½®è½¬
    create 0640 root root    # åˆ›å»ºæ–°æ–‡ä»¶çš„æƒé™
    sharedscripts
    postrotate
        docker-compose -f /opt/aggregator/docker-compose.yml restart aggregator > /dev/null 2>&1 || true
    endscript
}
```

### 6.2 æ—¥å¿—èšåˆ

#### âœ… **ä½¿ç”¨ ELK Stack**

```yaml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  aggregator:
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://logstash:5000"
```

### 6.3 æ—¥å¿—åˆ†æ

#### âœ… **ä½¿ç”¨ lnav åˆ†ææ—¥å¿—**

```bash
# å®‰è£… lnav
sudo apt-get install lnav

# åˆ†ææ—¥å¿—
docker-compose logs aggregator | lnav

# æˆ–ç›´æ¥åˆ†ææ—¥å¿—æ–‡ä»¶
lnav /opt/aggregator/logs/*.log
```

---

## 7. èµ„æºç®¡ç†

### 7.1 ç£ç›˜ç©ºé—´ç®¡ç†

#### âœ… **å®šæœŸæ¸…ç†**

åˆ›å»º `/opt/aggregator/scripts/cleanup.sh`ï¼š

```bash
#!/bin/bash
set -e

echo "ğŸ§¹ å¼€å§‹æ¸…ç†..."

# 1. æ¸…ç† Docker ç¼“å­˜
echo "1ï¸âƒ£ æ¸…ç† Docker ç¼“å­˜..."
docker system prune -a -f --volumes
DOCKER_FREED=$(docker system df | tail -1 | awk '{print $4}')
echo "   é‡Šæ”¾: $DOCKER_FREED"

# 2. æ¸…ç†æ—§æ—¥å¿—
echo "2ï¸âƒ£ æ¸…ç†æ—§æ—¥å¿—..."
find /opt/aggregator/logs -name "*.log" -mtime +30 -delete
find /opt/aggregator/logs -name "*.log.gz" -mtime +90 -delete

# 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
echo "3ï¸âƒ£ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
rm -rf /opt/aggregator/data/temp/*

# 4. æ¸…ç†æ—§å¤‡ä»½
echo "4ï¸âƒ£ æ¸…ç†æ—§å¤‡ä»½..."
find /opt/aggregator/backups -name "backup_*.tar.gz" -mtime +30 -delete

echo "âœ… æ¸…ç†å®Œæˆï¼"
df -h /
```

å®šæ—¶è¿è¡Œï¼š
```bash
# æ¯å‘¨æ—¥å‡Œæ™¨ 4 ç‚¹æ¸…ç†
0 4 * * 0 /opt/aggregator/scripts/cleanup.sh >> /opt/aggregator/logs/cleanup.log 2>&1
```

### 7.2 ç›‘æ§ç£ç›˜ä½¿ç”¨

#### âœ… **ç£ç›˜ä½¿ç”¨å‘Šè­¦**

åˆ›å»º `/opt/aggregator/scripts/disk-monitor.sh`ï¼š

```bash
#!/bin/bash

THRESHOLD=80
WEBHOOK_URL="${WEBHOOK_URL:-}"

# æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡
USAGE=$(df -h / | tail -1 | awk '{print $5}' | sed 's/%//')

if [ "$USAGE" -gt "$THRESHOLD" ]; then
    MESSAGE="âš ï¸ ç£ç›˜ä½¿ç”¨ç‡ ${USAGE}% è¶…è¿‡é˜ˆå€¼ ${THRESHOLD}%"
    
    # å‘é€é€šçŸ¥
    if [ -n "$WEBHOOK_URL" ]; then
        curl -X POST "$WEBHOOK_URL" -d "$MESSAGE"
    fi
    
    echo "$MESSAGE"
fi
```

---

## 8. ç½‘ç»œé…ç½®

### 8.1 DNS é…ç½®

#### âœ… **é…ç½®å¯é çš„ DNS**

```yaml
services:
  aggregator:
    dns:
      - 8.8.8.8          # Google DNS
      - 1.1.1.1          # Cloudflare DNS
      - 223.5.5.5        # é˜¿é‡Œ DNSï¼ˆå›½å†…ï¼‰
```

### 8.2 ä»£ç†é…ç½®

#### âœ… **ä¸ºå®¹å™¨é…ç½®ä»£ç†**

```yaml
services:
  aggregator:
    environment:
      - HTTP_PROXY=http://proxy-server:8080
      - HTTPS_PROXY=http://proxy-server:8080
      - NO_PROXY=localhost,127.0.0.1
```

---

## 9. æ•…éšœæ¢å¤

### 9.1 è‡ªåŠ¨æ¢å¤

#### âœ… **é…ç½®å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨é‡å¯**

```yaml
services:
  aggregator:
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
```

### 9.2 ç¾éš¾æ¢å¤è®¡åˆ’

#### âœ… **å®Œæ•´çš„æ¢å¤æµç¨‹**

1. **å‡†å¤‡æ¢å¤ç¯å¢ƒ**
```bash
# å®‰è£… Docker å’Œ Docker Compose
curl -fsSL https://get.docker.com | bash
```

2. **æ¢å¤é…ç½®**
```bash
# ä»å¤‡ä»½æ¢å¤é…ç½®æ–‡ä»¶
scp user@backup-server:/backups/aggregator/.env ./
scp user@backup-server:/backups/aggregator/docker-compose.yml ./
```

3. **æ¢å¤æ•°æ®**
```bash
# ä»å¤‡ä»½æ¢å¤æ•°æ®
mkdir -p data logs
scp user@backup-server:/backups/aggregator/backup_latest.tar.gz ./
tar -xzf backup_latest.tar.gz -C ./data
```

4. **å¯åŠ¨æœåŠ¡**
```bash
docker-compose up -d
```

5. **éªŒè¯æœåŠ¡**
```bash
docker-compose ps
docker-compose logs -f aggregator
```

---

## 10. å¼€å‘ç¯å¢ƒå®è·µ

### 10.1 æœ¬åœ°å¼€å‘

#### âœ… **ä½¿ç”¨ docker-compose override**

åˆ›å»º `docker-compose.override.yml`ï¼š

```yaml
version: '3.8'

services:
  aggregator:
    # å¼€å‘ç¯å¢ƒä½¿ç”¨ latest æ ‡ç­¾
    image: wzdnzd/aggregator:latest
    
    # æŒ‚è½½ä»£ç ç›®å½•ï¼ˆç”¨äºå¼€å‘ï¼‰
    volumes:
      - ./subscribe:/aggregator/subscribe:ro
      - ./data:/aggregator/data
      - ./logs:/aggregator/logs
    
    # å¯ç”¨ DEBUG æ¨¡å¼
    environment:
      - LOG_LEVEL=DEBUG
      - PYTHONUNBUFFERED=1
    
    # å¼€å‘ç¯å¢ƒä¸é™åˆ¶èµ„æº
    # deploy: {}
```

### 10.2 æµ‹è¯•ç¯å¢ƒ

#### âœ… **ç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ**

```yaml
# docker-compose.test.yml
version: '3.8'

services:
  aggregator-test:
    image: wzdnzd/aggregator:main
    container_name: aggregator-test
    environment:
      - GIST_PAT=${GIST_PAT_TEST}
      - GIST_LINK=${GIST_LINK_TEST}
    volumes:
      - ./test-data:/aggregator/data
    networks:
      - test-network

networks:
  test-network:
    driver: bridge
```

å¯åŠ¨æµ‹è¯•ç¯å¢ƒï¼š
```bash
docker-compose -f docker-compose.test.yml up -d
```

---

## ğŸ“š å‚è€ƒèµ„æº

- ğŸ“– [å®Œæ•´å®‰è£…æŒ‡å¼•](./INSTALLATION.md)
- ğŸ› [è¯¦ç»†è°ƒè¯•æŒ‡å¼•](./DEBUG.md)
- ğŸ“‹ [å¿«é€Ÿå‚è€ƒå¡](./QUICK_REFERENCE.md)
- ğŸŒ³ [é—®é¢˜è¯Šæ–­æ ‘](./TROUBLESHOOTING_TREE.md)

---

**ğŸ“ æ–‡æ¡£æ›´æ–°**: 2024-11  
**âœï¸ ä½œè€…**: wzdnzd  
**ğŸ”— é¡¹ç›®åœ°å€**: https://github.com/wzdnzd/aggregator
